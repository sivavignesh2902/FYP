{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['playing', 'frog', 'dog']\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "rake_nltk_var = Rake()\n",
    "text = \"\"\"frog and dog is playing\"\"\"\n",
    "rake_nltk_var.extract_keywords_from_text(text)\n",
    "keyword_extracted = rake_nltk_var.get_ranked_phrases()\n",
    "print(keyword_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('frog', 'NN'), ('and', 'CC'), ('dog', 'NN'), ('is', 'VBZ'), ('playing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "tokenized = word_tokenize(text)\n",
    "\n",
    "tagged = nltk.pos_tag(tokenized)\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for finding the sentiment of the sentence\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "def retSetiment(text1):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    user_input = text1\n",
    "    \n",
    "    sentiment_scores = analyzer.polarity_scores(user_input)\n",
    "\n",
    "    if sentiment_scores['compound'] >= 0.05:\n",
    "        sentiment = \"positive\"\n",
    "    elif sentiment_scores['compound'] <= -0.05:\n",
    "        sentiment = \"negative\"\n",
    "    else:\n",
    "        sentiment = \"neutral\"\n",
    "\n",
    "    print(f\"Sentiment: {sentiment}\")\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n",
      "Sentiment: positive\n",
      "colorful frog and cute dog is playing\n",
      "\n",
      "vibrant frog and cute dog dog is playing\n",
      "\n",
      "striking frog and cute dog dog dog is playing\n",
      "\n",
      "tropical frog and cute dog dog dog dog is playing\n",
      "\n",
      "colorful frog and active dog is playing\n",
      "\n",
      "vibrant frog and active dog dog is playing\n",
      "\n",
      "striking frog and active dog dog dog is playing\n",
      "\n",
      "tropical frog and active dog dog dog dog is playing\n",
      "\n",
      "colorful frog and happy dog is playing\n",
      "\n",
      "vibrant frog and happy dog dog is playing\n",
      "\n",
      "striking frog and happy dog dog dog is playing\n",
      "\n",
      "tropical frog and happy dog dog dog dog is playing\n",
      "\n",
      "colorful frog and obedient dog is playing\n",
      "\n",
      "vibrant frog and obedient dog dog is playing\n",
      "\n",
      "striking frog and obedient dog dog dog is playing\n",
      "\n",
      "tropical frog and obedient dog dog dog dog is playing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def appendAdj(extNoun):\n",
    "    extNoun=extNoun.lower()\n",
    "    animals_adj = open(\"./data.json\")\n",
    "    ani_json = json.load(animals_adj)\n",
    "    name_adj_dict = {}\n",
    "    ani_json = ani_json['animals']\n",
    "    sentSentiment = retSetiment(text) #negative\n",
    "    currAdj = []\n",
    "    for i in ani_json:\n",
    "        if(i['name'] == extNoun):\n",
    "            for j in  range(len(i['adjectives'])):\n",
    "                if(i['adjectives'][j][\"type\"] == sentSentiment):\n",
    "                    currAdj.append(i['adjectives'][j][\"value\"])\n",
    "                    \n",
    "    name_adj_dict[extNoun] = currAdj\n",
    "   \n",
    "    return name_adj_dict[extNoun]\n",
    "    \n",
    "    \n",
    "    \n",
    "allAdj = {}\n",
    "allText = []\n",
    "\n",
    "k=0\n",
    "\n",
    "for i,j in (tagged):\n",
    "    if(j=='NN'):\n",
    "        allAdj[i] = appendAdj(i)\n",
    "# for i in allAdj:\n",
    "#     print(i,\" \",allAdj[i])\n",
    "allText.append([])\n",
    "allText[0]=[text]\n",
    "length=1\n",
    "for k in allAdj:\n",
    "    allText.append([])\n",
    "    if(allAdj[k] == []):\n",
    "        continue\n",
    "    for v1 in allAdj[k]:\n",
    "        for m in allText[length-1]:\n",
    "            v1 += \" \" + k\n",
    "            allText[length].append(re.sub(k,v1,m))\n",
    "    length+=1\n",
    "for i in allText[length-1]:\n",
    "    print(i+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\FYP\\prompt_generator\\main.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/FYP/prompt_generator/main.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/FYP/prompt_generator/main.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjoblib\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/FYP/prompt_generator/main.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mHabitatPred\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocess_text\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/FYP/prompt_generator/main.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m fdata \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m./data.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/FYP/prompt_generator/main.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m fdata \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(fdata)\n",
      "File \u001b[1;32me:\\FYP\\prompt_generator\\HabitatPred.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m \u001b[39mimport\u001b[39;00m TfidfVectorizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import joblib\n",
    "from HabitatPred import preprocess_text\n",
    "\n",
    "fdata = open('./data.json')\n",
    "fdata = json.load(fdata)\n",
    "fdata = fdata['animals']\n",
    "\n",
    "def checkAndReturnHabitat(extNoun):\n",
    "    for i in fdata:\n",
    "        if(i['name'] == extNoun):\n",
    "            # print(i['habitats'])\n",
    "            return i['habitats']\n",
    "    return []\n",
    "\n",
    "def isHabitat(extNoun):\n",
    "    model = joblib.load('habitatModel.pkl')\n",
    "    vectorizer = joblib.load('vectorModel.pkl')\n",
    "\n",
    "    user_input = extNoun\n",
    "\n",
    "    user_input_preprocessed = preprocess_text(user_input)\n",
    "\n",
    "    user_input_vec = vectorizer.transform([user_input_preprocessed])\n",
    "\n",
    "    prediction = model.predict(user_input_vec)\n",
    "\n",
    "    if prediction[0] == 1:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "#habitat inclusion\n",
    "currAllText = allText[length-1]\n",
    "newAllText = []\n",
    "setHabitats = []\n",
    "\n",
    "flag = True\n",
    "for i,j in (tagged):\n",
    "    if ((j == 'NN') and (isHabitat(j) == False)):\n",
    "        flag = False\n",
    "    else:\n",
    "        flag = True\n",
    "        break\n",
    "    \n",
    "#if there is no habitat found in the sentence\n",
    "if flag == False:\n",
    "    for i,j in (tagged):\n",
    "        if ((j == 'NN') and (isHabitat(j) == False)): #dog\n",
    "            setHabitats = checkAndReturnHabitat(i)\n",
    "            if(setHabitats == []):\n",
    "                continue\n",
    "            for l in currAllText:\n",
    "                for k in setHabitats:\n",
    "                    temp = l\n",
    "                    temp += \", in the \" + k\n",
    "                    newAllText.append(temp)\n",
    "    for i in newAllText:\n",
    "        print(i,end = \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text)\n",
    "def cosineTop10(allText1):\n",
    "    maxDict1 = {}\n",
    "    top10Sentences = []\n",
    "    for i in allText1:\n",
    "        col1=[i]\n",
    "        col2=[text]\n",
    "        vectors1 = model.encode(col1, convert_to_tensor=True)\n",
    "        vectors2 = model.encode(col2, convert_to_tensor=True)\n",
    "        cosine_scores = util.cos_sim(vectors1, vectors2)\n",
    "        for j,(sent1,sent2) in enumerate(zip(col1,col2)):\n",
    "            if cosine_scores[j][j]>=0.5:\n",
    "                maxDict1[i] = cosine_scores[j][j]\n",
    "    l1 = 10\n",
    "    ind1 = 0\n",
    "    for k, v in sorted(maxDict1.items(), key=lambda item: item[1],reverse=True):\n",
    "        if(ind1 >= l1 or ind1 >= len(maxDict1)):\n",
    "            break\n",
    "        ind1+=1\n",
    "        top10Sentences.append(k)\n",
    "    return top10Sentences \n",
    "topSentences = cosineTop10(allText[length-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiny frog is crying, in a forest\n"
     ]
    }
   ],
   "source": [
    "for i in topSentences:\n",
    "    print(i,end = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependecy identification and Tree Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiny: amod -> frog\n",
      "frog: nsubj -> crying\n",
      "is: aux -> crying\n",
      "crying: ROOT -> crying\n",
      ",: punct -> crying\n",
      "in: prep -> crying\n",
      "a: det -> forest\n",
      "forest: pobj -> in\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'ext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\FYP\\prompt_generator\\main.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/FYP/prompt_generator/main.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sentence \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcat in the house and drinking milk which is stolen by other cats\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/FYP/prompt_generator/main.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp(sentence)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/FYP/prompt_generator/main.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(doc\u001b[39m.\u001b[39;49mext)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'ext'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentence = \"cat in the house and drinking milk which is stolen by other cats\"\n",
    "doc = nlp(sentence)\n",
    "print(doc.ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frog\n",
      "{'name': 'Frog', 'adjectives': ['colorful', 'poisonous', 'tiny', 'vibrant', 'striking', 'tropical'], 'habitats': ['rainforests', 'jungles', 'tropical forests']}\n",
      "{'name': 'Eagle', 'adjectives': ['majestic', 'imposing', 'predatory', 'large', 'powerful', 'elegant'], 'habitats': ['tropical rainforests', 'dense jungles', 'remote forested regions']}\n",
      "{'name': 'Jaguar', 'adjectives': ['powerful', 'ferocious', 'spotted', 'solitary', 'elusive', 'carnivorous'], 'habitats': ['rainforests', 'swamps', 'grasslands']}\n",
      "{'name': 'Toucan', 'adjectives': ['colorful', 'tropical', 'vibrant', 'beak-shaped', 'noisy', 'fruit-eating'], 'habitats': ['rainforests', 'tropical forests', 'jungles']}\n",
      "{'name': 'Sloth', 'adjectives': ['slow-moving', 'tree-dwelling', 'peaceful', 'herbivorous', 'folivorous', 'sleepy'], 'habitats': ['tropical rainforests', 'canopy', 'forested regions']}\n",
      "{'name': 'Orangutan', 'adjectives': ['intelligent', 'solitary', 'arboreal', 'ginger-haired', 'strong', 'endangered'], 'habitats': ['rainforests', 'tropical forests', 'swamps']}\n",
      "{'name': 'Proboscis Monkey', 'adjectives': ['unique', 'arboreal', 'nosey', 'endemic', 'social', 'folivorous'], 'habitats': ['mangrove forests', 'swamps', 'coastal areas']}\n",
      "{'name': 'Kangaroo', 'adjectives': ['arboreal', 'endearing', 'marsupial', 'climbing', 'furry', 'unique'], 'habitats': ['tropical rainforests', 'mountainous regions', 'dense forests']}\n",
      "{'name': 'Gorilla', 'adjectives': ['powerful', 'intelligent', 'gentle', 'strong', 'endangered', 'social'], 'habitats': ['rainforests', 'mountain forests', 'bamboo thickets']}\n",
      "{'name': 'Aye-Aye', 'adjectives': ['unusual', 'nocturnal', 'long-fingered', 'endangered', 'solitary', 'shaggy'], 'habitats': ['rainforests', 'deciduous forests', 'coastal forests']}\n",
      "{'name': 'Okapi', 'adjectives': ['striking', 'solitary', 'elusive', 'forest-dwelling', 'unique', 'camouflaged'], 'habitats': ['Congo rainforests', 'dense jungles', 'tropical forests']}\n",
      "{'name': 'Anaconda', 'adjectives': ['gigantic', 'powerful', 'constricting', 'aquatic', 'prehistoric', 'sleek'], 'habitats': ['Amazon rainforest', 'swamps', 'rivers', 'wetlands']}\n",
      "{'name': 'Mandrill', 'adjectives': ['colorful', 'vibrant', 'gregarious', 'intelligent', 'distinctive', 'forest-dwelling'], 'habitats': ['rainforests', 'jungles', 'tropical forests']}\n",
      "{'name': 'Red-eyed Tree Frog', 'adjectives': ['vibrant', 'colorful', 'arboreal', 'nocturnal', 'striking', 'amphibious'], 'habitats': ['rainforests', 'tropical jungles', 'lowland forests']}\n",
      "{'name': 'Anteater', 'adjectives': ['long-snouted', 'insectivorous', 'nocturnal', 'solitary', 'curious', 'clumsy'], 'habitats': ['rainforests', 'grasslands', 'woodlands']}\n",
      "{'name': 'Scarlet Macaw', 'adjectives': ['colorful', 'vibrant', 'majestic', 'tropical', 'loud', 'striking'], 'habitats': ['rainforests', 'jungles', 'tropical forests']}\n",
      "{'name': 'Leafcutter Ant', 'adjectives': ['industrious', 'small', 'cooperative', 'leaf-cutting', 'social', 'efficient'], 'habitats': ['rainforests', 'forests', 'tropical regions']}\n",
      "{'name': 'Fossa', 'adjectives': ['elusive', 'carnivorous', 'arboreal', 'endemic', 'sleek', 'solitary'], 'habitats': ['Madagascar', 'rainforests', 'deciduous forests']}\n",
      "{'name': 'Tapir', 'adjectives': ['gentle', 'herbivorous', 'shy', 'solitary', 'unusual', 'forest-dwelling'], 'habitats': ['rainforests', 'jungles', 'tropical forests', 'swamps', 'wetlands']}\n",
      "{'name': 'Kinkajou', 'adjectives': ['nocturnal', 'arboreal', 'frugivorous', 'curious', 'climbing', 'rainforest'], 'habitats': ['rainforests', 'tropical jungles', 'canopy forests']}\n",
      "{'name': 'Lion', 'adjectives': ['majestic', 'fierce', 'carnivorous', 'regal', 'territorial', 'powerful'], 'habitats': ['savannah', 'grasslands', 'jungles']}\n",
      "{'name': 'Siamang', 'adjectives': ['noisy', 'arboreal', 'black-furred', 'loud', 'social', 'long-armed'], 'habitats': ['tropical rainforests', 'dense forests', 'lowland swamps']}\n",
      "{'name': 'Blue Morpho Butterfly', 'adjectives': ['iridescent', 'blue-winged', 'graceful', 'tropical', 'vibrant', 'fluttering'], 'habitats': ['rainforests', 'tropical jungles', 'lush forests']}\n",
      "{'name': 'Glass Frog', 'adjectives': ['transparent', 'delicate', 'arboreal', 'green', 'unique', 'amphibious'], 'habitats': ['rainforests', 'cloud forests', 'tropical jungles']}\n",
      "{'name': 'Capybara', 'adjectives': ['social', 'semi-aquatic', 'gentle', 'herbivorous', 'large', 'amiable'], 'habitats': ['wetlands', 'swamps', 'grasslands']}\n",
      "{'name': 'Caiman', 'adjectives': ['ferocious', 'scaly', 'aquatic', 'predatory', 'reptilian', 'stealthy'], 'habitats': ['rivers', 'swamps', 'wetlands']}\n",
      "{'name': 'Quetzal', 'adjectives': ['vibrant', 'gorgeous', 'colorful', 'magnificent', 'resplendent', 'tropical'], 'habitats': ['cloud forests', 'tropical rainforests', 'mountainous regions']}\n",
      "{'name': 'Bengal Tiger', 'adjectives': ['striking', 'powerful', 'majestic', 'endangered', 'solitary', 'ferocious'], 'habitats': ['forests', 'swamps', 'grasslands']}\n",
      "{'name': 'Golden Lion Tamarin', 'adjectives': ['adorable', 'endangered', 'small', 'golden', 'social', 'tree-dwelling'], 'habitats': ['Atlantic coastal forests', 'tropical rainforests', 'wooded areas']}\n",
      "{'name': 'Dhole', 'adjectives': ['gregarious', 'canine', 'wild', 'endangered', 'social', 'nimble'], 'habitats': ['forests', 'grasslands', 'mountainous regions']}\n",
      "{'name': 'Green Tree Python', 'adjectives': ['vibrant', 'arboreal', 'beautiful', 'non-venomous', 'graceful'], 'habitats': ['rainforests', 'tropical canopies', 'tree branches']}\n",
      "{'name': 'Piranha', 'adjectives': ['aggressive', 'voracious', 'carnivorous', 'sharp-toothed', 'savage', 'swift'], 'habitats': ['Amazon River', 'tributaries', 'swamps']}\n",
      "{'name': 'Ocelot', 'adjectives': ['spotted', 'solitary', 'nocturnal', 'elusive', 'graceful', 'wild'], 'habitats': ['rainforests', 'dense jungles', 'thickets']}\n",
      "{'name': 'Mangrove Crab', 'adjectives': ['colorful', 'crustacean', 'mangrove-dwelling', 'burrowing', 'scavenging', 'brachyura'], 'habitats': ['mangrove forests', 'estuaries', 'coastal wetlands']}\n",
      "{'name': 'Amazon River Dolphin', 'adjectives': ['pink', 'freshwater', 'mysterious', 'inquisitive', 'elusive', 'unique'], 'habitats': ['Amazon River', 'Amazon Basin', 'tributaries']}\n",
      "{'name': 'Dolphin', 'adjectives': ['intelligent', 'graceful', 'aquatic', 'social', 'playful', 'curious'], 'habitats': ['ocean', 'seas', 'bays']}\n",
      "{'name': 'Giant River Otter', 'adjectives': ['aquatic', 'social', 'playful', 'nocturnal', 'endangered', 'vocal'], 'habitats': ['Amazon River', 'wetlands', 'riverine forests']}\n",
      "{'name': 'Tarsier', 'adjectives': ['small', 'nocturnal', 'tree-dwelling', 'big-eyed', 'insectivorous', 'acrobatic'], 'habitats': ['rainforests', 'forests', 'woodlands']}\n",
      "{'name': 'Saki Monkey', 'adjectives': ['elusive', 'arboreal', 'long-tailed', 'frugivorous', 'shy', 'rainforest-dwelling'], 'habitats': ['Amazon rainforest', 'South American jungles', 'tropical forests']}\n",
      "{'name': 'Blue-and-yellow Macaw', 'adjectives': ['colorful', 'vibrant', 'tropical', 'sociable', 'noisy', 'intelligent'], 'habitats': ['rainforests', 'tropical forests', 'swamps']}\n",
      "{'name': 'Emerald Tree Boa', 'adjectives': ['arboreal', 'striking', 'vibrant', 'coiled', 'nocturnal', 'camouflaged'], 'habitats': ['rainforests', 'tropical canopies', 'tree branches']}\n",
      "{'name': 'Goliath Beetle', 'adjectives': ['massive', 'striking', 'colorful', 'tropical', 'insectivorous', 'impressive'], 'habitats': ['rainforests', 'tropical jungles', 'deciduous forests']}\n",
      "{'name': 'Eagle', 'adjectives': ['majestic', 'soaring', 'predatory', 'keen-sighted', 'territorial', 'graceful'], 'habitats': ['mountains', 'cliffs', 'canyons']}\n",
      "{'name': 'Tiger', 'adjectives': ['striking', 'solitary', 'stealthy', 'endangered', 'ferocious', 'beautiful'], 'habitats': ['forests', 'swamps', 'grasslands']}\n",
      "{'name': 'Octopus', 'adjectives': ['flexible', 'intelligent', 'camouflaged', 'tentacled', 'invertebrate', 'elusive'], 'habitats': ['ocean', 'coral reefs', 'underwater caves']}\n",
      "{'name': 'Penguin', 'adjectives': ['adorable', 'fluffy', 'waddling', 'social', 'articulate', 'tuxedoed'], 'habitats': ['Antarctica', 'sub-Antarctic islands', 'coastal regions']}\n",
      "{'name': 'Giraffe', 'adjectives': ['tall', 'graceful', 'herbivorous', 'spotted', 'gentle', 'long-necked'], 'habitats': ['African savannah', 'woodlands', 'grasslands']}\n"
     ]
    }
   ],
   "source": [
    "#Algorithm implementation\n",
    "import json\n",
    "class Node:\n",
    "    def __init__(self,val,adj):\n",
    "        self.val = val #string\n",
    "        self.adj = adj #[]\n",
    "    def getVal(self):\n",
    "        return self.val\n",
    "\n",
    "class GoT:\n",
    "    def __init__(self,arr): # arr contains nsubj, dobj\n",
    "        \n",
    "        self.children = []\n",
    "    def createGraph(self):\n",
    "        for i in self.data_json:\n",
    "            n = Node(i[\"name\"])\n",
    "            self.children.append(Node(\"adjectives\"))\n",
    "            self.children.append(Node(\"habitats\"))\n",
    "                    \n",
    "                \n",
    "\n",
    "got = GoT([\"Tiger\",\"lion\"])\n",
    "got.createGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tall - (adjective)\n",
      "graceful - (adjective)\n",
      "herbivorous - (adjective)\n",
      "spotted - (adjective)\n",
      "gentle - (adjective)\n",
      "long-necked - (adjective)\n",
      "African savannah - (habitat)\n",
      "woodlands - (habitat)\n",
      "grasslands - (habitat)\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self, name, node_type):\n",
    "        self.name = name\n",
    "        self.node_type = node_type\n",
    "        self.children = []\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.name} - ({self.node_type})\"\n",
    "   \n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.nodes = []\n",
    "\n",
    "    def add_node(self, node):\n",
    "        self.nodes.append(node)\n",
    "\n",
    "    def add_edge(self, parent, child):\n",
    "        parent.add_child(child)\n",
    "\n",
    "    def get_children(self, node):\n",
    "        return node.children\n",
    "    def findNode(self,animalName):\n",
    "        for i in self.nodes:\n",
    "            if(i.node_type == 'animal' and i.name == animalName):\n",
    "                temp =  self.get_children(i)\n",
    "                return temp\n",
    "        return []\n",
    "# Create a graph\n",
    "graph = Graph()\n",
    "data = open('./data.json')\n",
    "\n",
    "data_json = json.load(data)\n",
    "\n",
    "data_json = data_json['animals']\n",
    "\n",
    "root = Node(\"animal\", \"root\")\n",
    "graph.add_node(root)\n",
    "for i in range(len(data_json)):\n",
    "    n1 = Node(data_json[i]['name'],\"animal\")\n",
    "    graph.add_node(n1)\n",
    "    for adj in data_json[i][\"adjectives\"]:\n",
    "        adjective_node = Node(adj, \"adjective\")\n",
    "        graph.add_node(adjective_node)\n",
    "        graph.add_edge(n1, adjective_node)\n",
    "\n",
    "    for habitat in data_json[i][\"habitats\"]:\n",
    "        habitat_node = Node(habitat, \"habitat\")\n",
    "        graph.add_node(habitat_node)\n",
    "        graph.add_edge(n1, habitat_node)\n",
    "\n",
    "testAnimal = \"Giraffe\"\n",
    "cdren = graph.findNode(testAnimal)\n",
    "if(cdren != []):\n",
    "    for i in cdren:\n",
    "        print(i)\n",
    "else:\n",
    "    print(\"Not Found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
